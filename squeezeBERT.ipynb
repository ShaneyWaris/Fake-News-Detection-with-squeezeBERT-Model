{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, GPT2Tokenizer, RobertaTokenizer, XLMTokenizer, XLMModel, XLNetTokenizer, XLNetModel, SqueezeBertTokenizer, SqueezeBertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training is started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cdc currently reports NUM deaths general discr...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>states reported NUM deaths small rise last tue...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>politically correct woman almost uses pandemic...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NUM testing laboratories india NUMth august NU...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>populous states generate large case counts loo...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  cdc currently reports NUM deaths general discr...  real\n",
       "1   2  states reported NUM deaths small rise last tue...  real\n",
       "2   3  politically correct woman almost uses pandemic...  fake\n",
       "3   4  NUM testing laboratories india NUMth august NU...  real\n",
       "4   5  populous states generate large case counts loo...  real"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_preprocessed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pre-trained model.\n",
    "tokenizer = SqueezeBertTokenizer.from_pretrained('squeezebert/squeezebert-mnli-headless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
      "   Tokens: ['when', 'was', 'i', 'last', 'outside', '?', 'i', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
      "Token IDs: [2043, 2001, 1045, 2197, 2648, 1029, 1045, 2572, 5881, 2012, 2188, 2005, 1016, 3134, 1012]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n",
    "\n",
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')\n",
    "len(tokens), len(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Xtrain feature vector for train data.\n",
    "fv = []\n",
    "for txt in df.tweet:\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    convert = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    convert += [0]*(2859-len(convert))\n",
    "    fv.append(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the Ytrain vector for train data.\n",
    "labels = df.label.values\n",
    "labels = np.where(labels == 'fake', 0, labels)\n",
    "labels = np.where(labels == 'real', 1, labels)\n",
    "labels = list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now,\n",
    "# Xtrain = fv\n",
    "# Ytrain = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese converting islam realising muslim affe...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NUM NUM people diamond princess cruise ship in...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>covid NUM caused bacterium virus treated aspirin</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mike pence rnc speech praises donald trump cov...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NUM NUM sky explains latest data government an...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  chinese converting islam realising muslim affe...  fake\n",
       "1   2  NUM NUM people diamond princess cruise ship in...  fake\n",
       "2   3   covid NUM caused bacterium virus treated aspirin  fake\n",
       "3   4  mike pence rnc speech praises donald trump cov...  fake\n",
       "4   5  NUM NUM sky explains latest data government an...  real"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data.\n",
    "df_val = pd.read_csv(\"validation_preprocessed.csv\")\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Xtrain feature vector for Validation data.\n",
    "fv_val = []\n",
    "for txt in df_val.tweet:\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    convert = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    convert += [0]*(2859-len(convert))\n",
    "    fv_val.append(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the Ytrain vector for validation data.\n",
    "labels_val = df_val.label.values\n",
    "labels_val = np.where(labels_val == 'fake', 0, labels_val)\n",
    "labels_val = np.where(labels_val == 'real', 1, labels_val)\n",
    "labels_val = list(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now,\n",
    "# Xval = fv_val\n",
    "# Yval = labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>daily update published states reported NUMk te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alfalfa cure covid NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>president trump asked would catch coronavirus URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>states reported NUM deaths still seeing solid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>sixth time global health emergency declared in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet\n",
       "0   1  daily update published states reported NUMk te...\n",
       "1   2                             alfalfa cure covid NUM\n",
       "2   3  president trump asked would catch coronavirus URL\n",
       "3   4  states reported NUM deaths still seeing solid ...\n",
       "4   5  sixth time global health emergency declared in..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing data.\n",
    "df_test = pd.read_csv(\"test_data_preprocessed.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Xtrain feature vector for test data.\n",
    "fv_test = []\n",
    "for txt in df_test.tweet:\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    convert = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    convert += [0]*(2859-len(convert))\n",
    "    fv_test.append(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small test for feature vector.\n",
    "for i in range(0, len(fv)):\n",
    "    if len(fv[i])!=2859:\n",
    "        print(\"ohh shit!!\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      1019\n",
      "           1       0.75      0.83      0.79      1120\n",
      "\n",
      "    accuracy                           0.77      2139\n",
      "   macro avg       0.77      0.76      0.76      2139\n",
      "weighted avg       0.77      0.77      0.77      2139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model creation is started.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf = rf.fit(fv, labels)\n",
    "y_pred = rf.predict(fv_val)\n",
    "print(classification_report(labels_val, y_pred))\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# clf = AdaBoostClassifier()\n",
    "# clf = clf.fit(fv, labels)\n",
    "# y_pred = clf.predict(fv_test)\n",
    "# print(classification_report(labels_test, y_pred))\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# xgb = xgb.fit(np.array(fv), labels)\n",
    "# y_pred3 = xgb.predict(np.array(fv_test))\n",
    "# print(classification_report(labels_test, y_pred1))\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf = clf.fit(fv, labels)\n",
    "# y_predict = clf.predict(fv_test)\n",
    "# print(classification_report(labels_test, y_pred1))\n",
    "\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf = clf.fit(fv, labels)\n",
    "# y_predict = clf.predict(fv_test)\n",
    "# print(classification_report(labels_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"fv_train_squeezeBERT.csv\", fv, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"fv_val_squeezeBERT.csv\", fv_val, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"fv_test_squeezeBERT.csv\", fv_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
